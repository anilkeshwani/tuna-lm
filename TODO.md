# To Do

**Llama 3.2 1B Continued Pre-Training (CPT)**
- [ ] Set optimal batch size with gradient accumulation based on Llama 3.2 technical report
